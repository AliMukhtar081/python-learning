{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import numpy for numerical computations\n",
    "import numpy as np\n",
    "\n",
    "# Function to initialize weights of the neural network\n",
    "def initialize_nn(input_nodes, hidden_layers, nodes_per_layer, output_nodes):\n",
    "    np.random.seed(0)  # Set the seed for reproducibility\n",
    "    W_matrix = []  # Initialize an empty list to store weights\n",
    "\n",
    "    # Initialize weights between input layer and first hidden layer\n",
    "    input_to_hidden = np.random.randn(input_nodes, nodes_per_layer)\n",
    "    W_matrix.append(input_to_hidden)\n",
    "\n",
    "    # Initialize weights between hidden layers\n",
    "    for _ in range(hidden_layers - 1):\n",
    "        hidden_to_hidden = np.random.randn(nodes_per_layer, nodes_per_layer)\n",
    "        W_matrix.append(hidden_to_hidden)\n",
    "\n",
    "    # Initialize weights between last hidden layer and output layer\n",
    "    hidden_to_output = np.random.randn(nodes_per_layer, output_nodes)\n",
    "    W_matrix.append(hidden_to_output)\n",
    "\n",
    "    # Return the weight matrix\n",
    "    return W_matrix\n",
    "\n",
    "# Function for feedforward step\n",
    "def feedforward(input_data, W_matrix, hidden_layers):\n",
    "    layers = [input_data]  # Store input data\n",
    "    for i in range(hidden_layers + 1):\n",
    "        layer_input = layers[-1]  # Get input for current layer\n",
    "        # Compute output for current layer and apply sigmoid activation function\n",
    "        layer_output = sigmoid(np.dot(layer_input, W_matrix[i]))\n",
    "        layers.append(layer_output)  # Store output for current layer\n",
    "\n",
    "    # Return the layer outputs\n",
    "    return layers\n",
    "\n",
    "# Function for backpropagation step\n",
    "def backpropagation(output_data, layers, W_matrix, hidden_layers):\n",
    "    deltas = []  # Initialize list to store deltas\n",
    "    output_error = output_data - layers[-1]  # Calculate output error\n",
    "    output_delta = output_error * derivative_S(layers[-1])  # Calculate delta for output layer\n",
    "    deltas.append(output_delta)  # Store output delta\n",
    "\n",
    "    for i in range(hidden_layers, 0, -1):  # Loop over hidden layers in reverse order\n",
    "        # Calculate error for current hidden layer\n",
    "        hidden_error = np.dot(deltas[-1], W_matrix[i].T)\n",
    "        # Calculate delta for current hidden layer\n",
    "        hidden_delta = hidden_error * derivative_S(layers[i])\n",
    "        deltas.insert(0, hidden_delta)  # Store current hidden delta at the beginning of the list\n",
    "\n",
    "    # Return the deltas\n",
    "    return deltas\n",
    "\n",
    "# Function to update weights\n",
    "def update_weights(W_matrix, layers, deltas, learning_rate, hidden_layers):\n",
    "    for i in range(hidden_layers + 1):  # Loop over all layers\n",
    "        # Update weights for current layer\n",
    "        W_matrix[i] += learning_rate * np.dot(layers[i].T, deltas[i])\n",
    "    return W_matrix  # Return updated weights\n",
    "\n",
    "# Function to train the neural network\n",
    "def train_network(input_data, output_data, W_matrix, epochs, learning_rate, hidden_layers):\n",
    "    for epoch in range(epochs):  # Loop over epochs\n",
    "        layers = feedforward(input_data, W_matrix, hidden_layers)  # Perform feedforward step\n",
    "        deltas = backpropagation(output_data, layers, W_matrix, hidden_layers)  # Perform backpropagation step\n",
    "        W_matrix = update_weights(W_matrix, layers, deltas, learning_rate, hidden_layers)  # Update weights\n",
    "\n",
    "    # Return trained weights\n",
    "    return W_matrix\n",
    "\n",
    "# Function to run the trained network on input data\n",
    "def run(input_data, W_matrix, hidden_layers):\n",
    "    output_list = feedforward(input_data, W_matrix, hidden_layers)  # Get list of layer outputs\n",
    "    return np.round(output_list[-1])  # Round off the output of the final layer\n",
    "\n",
    "# Sigmoid activation function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))  # Return the sigmoid of x\n",
    "\n",
    "# Derivative of the sigmoid function\n",
    "def derivative_S(x):\n",
    "    return x * (1 - x)  # Return the derivative of the sigmoid of x\n",
    "\n",
    "# Define training data for XOR problem\n",
    "input_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "output_data = np.array([[0], [1], [1], [0]])\n",
    "\n",
    "# Define neural network architecture\n",
    "input_nodes = 2\n",
    "output_nodes = 1\n",
    "hidden_layers = 1\n",
    "nodes_per_layer = 2\n",
    "\n",
    "# Initialize the neural network\n",
    "W_matrix = initialize_nn(input_nodes, hidden_layers, nodes_per_layer, output_nodes)\n",
    "\n",
    "# Define training parameters\n",
    "epochs = 5000\n",
    "learning_rate = 0.1\n",
    "\n",
    "# Train the neural network\n",
    "W_matrix = train_network(input_data, output_data, W_matrix, epochs, learning_rate, hidden_layers)\n",
    "\n",
    "# Run the trained network on the input data and print the predictions\n",
    "predictions = run(input_data, W_matrix, hidden_layers)\n",
    "print(\"Predictions:\")\n",
    "for x, y in zip(input_data, predictions):\n",
    "    print(f\"Input: {x}, Output: {y}\")\n",
    " "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
